[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nSetting up a reproducible Julia, Python, R data analysis projects\n\n\n\n\n\n\njulia\n\n\ncoding setup\n\n\n\n\n\n\n\n\n\nDec 15, 2024\n\n\nBenjamin Doran\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Benjamin Doran",
    "section": "",
    "text": "Specializing in computational biology and machine learning, I am working on understanding the complex relationships that allow living things to adapt to new environments, form emergent structures and behaviors, and behave (semi) intellegently.\nAt a high level this entails asking: what are the fundamental principles of evolution that allow new behaviors and structures to develop in biological organisms? And, how can we apply these principles to better design synthetic biological systems with traits that benefit humanity and sustainable world?\nWhen not torturing my brain with challenging questions, I enjoy hiking, mountain biking, playing board games, photography, and cooking spicy food."
  },
  {
    "objectID": "index.html#bio",
    "href": "index.html#bio",
    "title": "Benjamin Doran",
    "section": "",
    "text": "Specializing in computational biology and machine learning, I am working on understanding the complex relationships that allow living things to adapt to new environments, form emergent structures and behaviors, and behave (semi) intellegently.\nAt a high level this entails asking: what are the fundamental principles of evolution that allow new behaviors and structures to develop in biological organisms? And, how can we apply these principles to better design synthetic biological systems with traits that benefit humanity and sustainable world?\nWhen not torturing my brain with challenging questions, I enjoy hiking, mountain biking, playing board games, photography, and cooking spicy food."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Benjamin Doran",
    "section": "Education",
    "text": "Education\nUniversity of Chicago, PME | Chicago IL\n\nPhD of Molecular Engineering | 2020 - 2025 (exp.)\n\nHarvard University, Harvard Extension School | Cambridge MA\n\nBachelor of Liberal Arts & Sciences, cum laude | 2014 - 2018\nProfessional Graduate Certificate in Data Science\nMinors: English & Computer Science\nHonors: Dean’s List Academic Achievment Award"
  },
  {
    "objectID": "index.html#publications",
    "href": "index.html#publications",
    "title": "Benjamin Doran",
    "section": "Publications",
    "text": "Publications\nAn evolution-based framework for describing human gut bacteria BioRxiv | Dec 5, 2023 https://doi.org/10.1101/2023.12.04.569969\nConcerted changes in the pediatric single-cell intestinal ecosystem before and after anti-TNF blockade eLife | Sep 22, 2023 https://doi.org/10.7554/eLife.91792.1\nMore Publications…"
  },
  {
    "objectID": "blogposts/001_setting-up-an-analysis-project.html",
    "href": "blogposts/001_setting-up-an-analysis-project.html",
    "title": "Setting up a reproducible Julia, Python, R data analysis projects",
    "section": "",
    "text": "I’ve found that one of the hardest aspects for people trying to start with scientific data analysis, is learning how to setup and organize an analysis project. This leads to problems where analysis can’t be reproduced – even by the same person – as well as headaches like missing data, or times a tool can’t be installed because of missing dependencies and conflicts with existing installations.\nSo, this document is meant as a record of the most convenient ways I’ve found set up a reproducible data analysis projects. The primary focus will be on creating these projects including the julia programming language, because that is the programming language I primarily use and this is listing my experience. As well as because there are already solid resources for when people are primarily using python and R. (those links are just examples, there are plenty more just a google search away.)\nSo, how do I do set up an analysis project for Julia?\n\n\n\n\n\n\nNote\n\n\n\nCaveat: I tend to use a Macbook Pro, so this setup example is based on that experience. That said, this tutorial should work for most systems, though windows users may need to adjust some of the initial install instructions. Once we get to the Julia specific portions, the instructions should be mostly platform agnostic.\n\n\n\n\n\n\n\n\nTip\n\n\n\nIt’s also worth pointing out Modern Julia Workflows for another set of opinions on how to work with Julia code."
  },
  {
    "objectID": "blogposts/001_setting-up-an-analysis-project.html#overview",
    "href": "blogposts/001_setting-up-an-analysis-project.html#overview",
    "title": "Setting up a reproducible Julia, Python, R data analysis projects",
    "section": "",
    "text": "I’ve found that one of the hardest aspects for people trying to start with scientific data analysis, is learning how to setup and organize an analysis project. This leads to problems where analysis can’t be reproduced – even by the same person – as well as headaches like missing data, or times a tool can’t be installed because of missing dependencies and conflicts with existing installations.\nSo, this document is meant as a record of the most convenient ways I’ve found set up a reproducible data analysis projects. The primary focus will be on creating these projects including the julia programming language, because that is the programming language I primarily use and this is listing my experience. As well as because there are already solid resources for when people are primarily using python and R. (those links are just examples, there are plenty more just a google search away.)\nSo, how do I do set up an analysis project for Julia?\n\n\n\n\n\n\nNote\n\n\n\nCaveat: I tend to use a Macbook Pro, so this setup example is based on that experience. That said, this tutorial should work for most systems, though windows users may need to adjust some of the initial install instructions. Once we get to the Julia specific portions, the instructions should be mostly platform agnostic.\n\n\n\n\n\n\n\n\nTip\n\n\n\nIt’s also worth pointing out Modern Julia Workflows for another set of opinions on how to work with Julia code."
  },
  {
    "objectID": "blogposts/001_setting-up-an-analysis-project.html#semi-optional-surrounding-tools",
    "href": "blogposts/001_setting-up-an-analysis-project.html#semi-optional-surrounding-tools",
    "title": "Setting up a reproducible Julia, Python, R data analysis projects",
    "section": "[semi-optional] Surrounding tools",
    "text": "[semi-optional] Surrounding tools\nPython and R are scripting languages which aim to be relatively easy and user friendly. Yet, as scripting languages they are relient on low-level compiled C and C++ code for performance. And, one of the common issues I see new coders face as they try to install scientific packages is not having compilers installed to handle the C and C++ code the python and R packages are using.\nThere are also a bunch of other basic tools that your editor may assume you have installed. So on Mac I usually recommend installing these programs to get the basic tools and compilers that are likely depended on by your editor and other packages.\n\nxcode command line tools\n\nrun xcode-select --install in the terminal to install git and other basic command line tools\n\nHomebrew: a package manager for Mac, helps to install additional command line tools as needed\nGithub SSH key for interacting with github (where many code packages are stored) without needing to type in a password every time.\n\nInstalling these three things will ease coding on mac, not just for Julia but also for Python and R."
  },
  {
    "objectID": "blogposts/001_setting-up-an-analysis-project.html#installing-julia",
    "href": "blogposts/001_setting-up-an-analysis-project.html#installing-julia",
    "title": "Setting up a reproducible Julia, Python, R data analysis projects",
    "section": "Installing Julia",
    "text": "Installing Julia\nFor julia, the recommended installation method is from juliaup. This allows easy installation of multiple julia versions and upgrading from one version to the next.\njuliaup is pretty easy to install from the command line on unix\ncurl -fsSL https://install.julialang.org | sh\nWindows has simple install instructions at the link as well.\nwinget install julia -s msstore\nThe latest release version of julia is then installed with juliaup with\njuliaup add release\nIt is usually already added when installing juliaup, but it doesn’t hurt to check that the version exists with\njuliaup status\nTo edit code, I use the vscode editor with the julia extension and quarto extension.\nInstall vscode here, and in the extensions tab you can install the julia extension following these instructions and install quarto using these instructions\nThese are the basic tools, from here I also install some julia specific tools to better manage my data analysis projects."
  },
  {
    "objectID": "blogposts/001_setting-up-an-analysis-project.html#julia-specific-setup",
    "href": "blogposts/001_setting-up-an-analysis-project.html#julia-specific-setup",
    "title": "Setting up a reproducible Julia, Python, R data analysis projects",
    "section": "Julia specific setup",
    "text": "Julia specific setup\nJulia’s default package manager is excellent. For package development it is basically complete, but for data analysis projects it can be made a bit better with the installation of two extra packages.\nFirst is DrWatson.jl which is a package specifically for data analysis projects. Like cookiecutter data science, DrWatson provides a template for reproducible analysis projects. And, helps to manage the local and relative filepaths in your projects.\nIt can be installed from the julia package mode. start julia in the terminal by typing julia and hitting enter.\nThen enter package mode by pressing ]\ninstall by typing in\nadd DrWatson\nexit package mode by pressing the backspace key.\nThe other package is useful if I am also using Python in my project, or have external commandline tools that are only available in the conda ecosystem. The package is CondaPkg.jl. And it allows installation of these python and conda tools in conjunction with the rest of my Julia code in completely reproducible way.\nInstall this package in the same way as DrWatson, by entering the julia package mode and typing in\nadd CondaPkg\nto use condapkg, we need to first load it\nexit package mode and type\nusing CondaPkg\nthen renter package mode and there is a new command conda ... that we can use that will add python and conda packages and store config files so that the analysis project knows exactly which versions have been loaded.\nFor those that this makes sense: It is a wrapper around micromamba and stores the environment requirements in a toml file that is readable by Julia and can be reproduced.\n# from CondaPkg docs\npkg&gt; conda status                # see what we have installed\npkg&gt; conda add python perl       # adds conda packages\npkg&gt; conda pip_add build         # adds pip packages\npkg&gt; conda rm perl               # removes conda packages\npkg&gt; conda run python --version  # runs the given command in the conda environment\npkg&gt; conda update                # update conda and pip installed packages\nTo negate the need to manually type in using CondaPkg whenever we restart julia, we can add\n@async @eval using CondaPkg\ninto ~/.julia/config/startup.jl (the default location julia is installed on unix systems), and CondaPkg will be loaded every time Julia restarts.\n\n\n\n\n\n\nImportant\n\n\n\nTo make sure the specific python and R versions as installed in the conda environment are accessible from vscode, we need to activate the environment before opening vscode.\nfrom the command line:\ncd path/to/project\nmicromamba activate ./.CondaPkg/env\ncode .\n\n\nalso I’ve had bad luck with installing all the R dependencies directly from conda. So I will usually only add\npkg&gt; conda add r-essentials r-irkernel\nthen create a seperate script that installs the rest of the R libraries I need either directly from R\nRScript scripts/install_dependencies.R\nwhere for example the scripts/install_dependencies.R is\noptions(repos=c(CRAN=\"https://repo.miserver.it.umich.edu/cran\"))\ninstall.packages(\"tidyverse\")\ninstall.packages(\"ggplot2\")\n\nif (!require(\"BiocManager\", quietly = TRUE)) {\n    install.packages(\"BiocManager\")\n}\n\nBiocManager::install(\"treeio\")\nBiocManager::install(\"ggtree\")\nOr from julia, if I am going to be calling R from julia a lot. For example:\nimport CondaPkg; \nCondaPkg.activate!(ENV);\nusing RCall\n\nR\"\"\"\noptions(repos=c(CRAN=\"https://repo.miserver.it.umich.edu/cran\"))\ninstall.packages(\"tidyverse\")\ninstall.packages(\"ggplot2\")\n\nif (!require(\"BiocManager\", quietly = TRUE)) {\n    install.packages(\"BiocManager\")\n}\n\nBiocManager::install(\"treeio\")\nBiocManager::install(\"ggtree\")\n\"\"\""
  },
  {
    "objectID": "blogposts/001_setting-up-an-analysis-project.html#project-specific-setup",
    "href": "blogposts/001_setting-up-an-analysis-project.html#project-specific-setup",
    "title": "Setting up a reproducible Julia, Python, R data analysis projects",
    "section": "Project specific setup",
    "text": "Project specific setup\nto use the project template provided by DrWatson, we first load it, then call the initialize_project() function.\nusing DrWatson\n# creates template project \"test_proj\" in folder `test_proj` as a sub-folder of the folder where we started julia\ninitialize_project(\"test_proj\") \nGenerally I like to have one folder where I store all my coding and analysis projects. I locate this in my home directory.\nfrom the command line I write mkdir -p ~/projects to create this folder.\nThen I could either start julia from within that folder, and use the previous commands to create a project directory in that folder.\nOr, if I started julia from somewhere else, I can tell julia to change the folder it’s started in by running cd(\"~/projects\"). And then I can run initialize_project(\"test_proj\") and get my template project created in the correct spot.\nLets open this folder in vscode.\nEither start vscode first, hit CMD+o open the folder selector and select your template project.\nOr with the vscode launcher, from the command line type code ~/projects/test_proj, which will start vscode with the project open.\nTo install the command line launcher, start vscode, hit CMD+SHIFT+p. In the search bar that pop up type code, and click on the Shell Command: Install 'code' command in PATH\nWith the template project created we should see these directories\ntest_proj % tree\n.\n├── Manifest.toml\n├── Project.toml\n├── README.md\n├── _research\n├── data\n│   ├── exp_pro\n│   ├── exp_raw\n│   └── sims\n├── notebooks\n├── papers\n├── plots\n├── scripts\n│   └── intro.jl\n├── src\n│   └── dummy_src_file.jl\n└── test\n    └── runtests.jl\n\n12 directories, 6 files\nSee DrWatson.jl for more in depth descriptions. But basically, Project.toml, and Manifest.toml are computer generated configuration files so that as we add packages to our project, they will store which packages and versions we have installed. If we use CondaPkg to install a package a new configuration file CondaPkg.toml will be created that stores listings of those packages and versions.\nAs an example lets add CondaPkg to our project environment.\nHit CONTROL+` this will open up the terminal within vscode, usually already located at your project folder.\nType in julia, to start the julia REPL (read; evaluate; print; loop) in the terminal. enter package mode by hitting ].\nYou should see\n(@v1.11) pkg&gt; \nwhere in parentheses is the version number of julia you installed. As of December 2024 the latest release version is v1.11. This indicates that you are in the global julia environment. You could install and load packages from here but they would not be reproducible for others or yourself if they clone your project.\nInstead, we will activate the project environment. the easiest what is by typing\nactivate .\nwhere the . indicates the current working directory.\nAlternatively type activate ~/projects/test_proj to activate the environment from anywhere.\nYou should now see\n(test_proj) pkg&gt; \nIf we now add CondaPkg or any other julia package they will be installed into the project environment.\nType add CondaPkg into the prompt and hit enter.\nAfter it is installed, if you open Project.toml, you should see\n[deps]\nCondaPkg = \"992eb4ea-22a4-4c89-a5bb-47a3300528ab\"\nDrWatson = \"634d3b9d-ee7a-5ddf-bec9-22491ea816e1\"\nas well as some other configurations.\nThis is a useful section to look at just to check if the packages you think are installed in your project are in fact installed in the project. The specifics of the versions installed are in the Manifest.toml file.\nFor the most part, you won’t need to look at these files, but they are how the project is made reproducible.\nThe README.md file in the template project has basic instructions for how the project can be cloned and instantiated on another computer."
  },
  {
    "objectID": "blogposts/001_setting-up-an-analysis-project.html#layout-of-project",
    "href": "blogposts/001_setting-up-an-analysis-project.html#layout-of-project",
    "title": "Setting up a reproducible Julia, Python, R data analysis projects",
    "section": "Layout of project",
    "text": "Layout of project\n\nmain important folders\nFor how I like to work in my projects, the two most important folders are the data/exp_raw and notebooks.\ndata/exp_raw is where data generally first enters the project. Downloaded datasets, or unprocessed data should go in here. Generally, I like to create a subfolder in here for each dataset, like data/exp_raw/&lt;dataset_1&gt; or usually something a bit more memorable. and then all files associated with that dataset, go in that folder.\nnotebooks is ignored by git (version control software) by default in the template project. So usually the first thing I do is comment out this line in the .gitignore file\n# /notebooks\nThe reason is that notebooks have a tendency to get large. I usually don’t hit the 100mb per file limit on github though so I find it more useful to version control the notebooks.\nIn this folder I use juptyer notebooks to run analysis in Julia, Python, and R. As a naming scheme I usually do &lt;incrementing number&gt;_&lt;language&gt;_&lt;description&gt;.ipynb. for example 00_jl_setupdata.ipynb.\nI tend to prefer using these notebooks because the plots are stored inline with the file. So, if I need to remember some visual, that I didn’t think to save at the time, the plot still exists in the notebook. It also means that I don’t need to re-run potentially quite long computations, every time I need to go back and remember a plot.\nThe notebooks also integrate well with Quarto which enables generating static HTML pages of each notebook, without needing to rerun every notebook or script for every re-render.\n\n\nother folders\nplots stores plots, I usually create a subfolder in here for each notebook.\nscripts similar to notebooks any set of code that is writing out files or plots, should probably be in here, I use this for scripts that I dispatch to the university SLURM cluster or AWS.\nsrc should only contain function declarations, i.e. code that I re-use across notebooks. If I am being fancy and developing custom analysis code that I will be using across projects, I will generate a full julia package and stick it in here as a git submodule. That is more advanced usage than we need to get into at the moment.\ndata/exp_pro and _research are both folders I use as output directories. Usually again with a subfolder for each analysis, that might mean multiple sub-folders per notebook. Best practice is probably to use _research for more in progress outputs. And then once the output is stabilized, write it to data/exp_pro. I tend to use data/exp_pro for cleaned data that I will be using again in other notebooks, whereas _research I tend to put final results. i.e. the outputs of statistical tests, etc.\ntests This is meant for testing the functions written in src, to ensure correctness. I tend to create a full package in the src directory and use the tests folder in there. It could also be used to automate reproducing the project, but I have not fully explored that option.\npapers The intended purpose per DrWatson is for “Scientific papers resulting from the project.” I don’t use it much till the end.\n\n\nadditional folder that I create\nI will sometimes create some additional folders\nreference for reference papers or other documents\ndocs autogenerated output from quarto of my notebooks\nwetlab_experiments protocols and lab notes for experiments I am running related to the analysis project.\nGenerally I also add these folders to the .gitignore file because they are often more internal notes.\n/reference\n/docs\n/wetlab_experiments"
  },
  {
    "objectID": "blogposts/001_setting-up-an-analysis-project.html#starting-the-project",
    "href": "blogposts/001_setting-up-an-analysis-project.html#starting-the-project",
    "title": "Setting up a reproducible Julia, Python, R data analysis projects",
    "section": "Starting the project",
    "text": "Starting the project\nThis will depend a lot on what kind of analysis I am doing, I usually add packages as I need them to the project environment.\nUsually to start I have some raw, CSV file in /data/exp_raw/initial_dataset.\nIn the terminal I will start julia and enter the package mode for my project and install some package that I know I will need, this is usually some subset of these packages\njulia\n]\npkg&gt; activate .\n(test_proj) pkg&gt; add CSV, DataFramesMeta # packages for working with tabular data\n(test_proj) pkg&gt; add StatsBase, LinearAlgebra # a bunch of standard statistics and basic linear algebra tooling\n(test_proj) pkg&gt; add SpectralInference # My package working  for working with SVD decompositions of datasets\n(test_proj) pkg&gt; add NewickTree # barebones package for working with newick style phylogenetic trees.\n(test_proj) pkg&gt; add NeighborJoining # My package implementing basic neighborjoining in julia\n(test_proj) pkg&gt; add Muon # julia interface for working with h5ad and h5mu file (useful files for storing matrix data with associated metadata)\n(test_proj) pkg&gt; add HypothesisTests, MultipleTesting # standard statistical tests and multiple testing corrections\n(test_proj) pkg&gt; add StatsPlots # lighter weight plotting package, concise syntax for plotting\n(test_proj) pkg&gt; add CairoMakie # part of the https://docs.makie.org/stable/ ecosystem for plotting. in active development and starting to get more advanced than StatsPlots, can make prettier plots, needs a bit more code\n(test_proj) pkg&gt; add LaTeXStrings # for adding latex captions and labels to plots\n\n# I use these intermittently/less, but are still worth the mention\n(test_proj) pkg&gt; add UMAP # umap dimension reduction of large datasets\n(test_proj) pkg&gt; add Symbolics # symbolic algebra in Julia\n(test_proj) pkg&gt; add MLJ # analog of scikit-learn, enables access to a whole bunch of standard machine learning models\n(test_proj) pkg&gt; add Flux # or Lux # basic deep learning toolkits in Julia\n(test_proj) pkg&gt; add SciML # differential equation solving and simulation\n(test_proj) pkg&gt; add Pluto # reactive notebooks, similar to jupyter notebooks but cells automatically re-compute, It's really useful for creating interactive dashboards for exploring small datasets\nAfter installing the packages I want at the moment to start with\nadd CSV, DataFramesMeta, StatsBase, StatsPlots\nSo, I will create a notebook\n00_jl_startcleaningdata.ipynb\nAs the first cell of the notebook I will create a markdown cell and add some metadata\n---\ntitle: Intial analysis cleaning data\nauthor: Benjamin Doran\ndate: today\n---\nThis will be used by quarto later when rendering as a static document.\nBelow that I create a code cell with\nusing DrWatson # load DrWatson from global environment\n@quickactivate projectdir() # this activates the project environment so we can load the correct packages\n# this way of activation works in the notebooks folder and most subfolders of the project.\n# for the activation to work anywhere on the computer explicitly write\n# @quickactivate \"test_proj\"\n\n# now we can load our packages from the package environment\nusing CSV, DataFrames, StatsPlots\n# I like this as a basic plotting theme\ntheme(:default, grid=false, tickdir=:out, label=false)\n\n# if we had individual files in `src` that we want to use\n#\n# include(srcdir(\"helpers.jl\")) \n#\n# usually this include line needs to be rerun if the file is adjusted, \n# using Revise (https://timholy.github.io/Revise.jl/stable/), \n# it might be possible to automatically reload the file on each save.\n\n# any other package config code\nddir = datadir(\"exp_raw\", \"initial_dataset\")\nAnd then I in the cells below I can write any analysis code I want, to read in, analyze, and plot the dataset."
  },
  {
    "objectID": "blogposts/001_setting-up-an-analysis-project.html#optional-set-up-quarto-website-of-analysis",
    "href": "blogposts/001_setting-up-an-analysis-project.html#optional-set-up-quarto-website-of-analysis",
    "title": "Setting up a reproducible Julia, Python, R data analysis projects",
    "section": "[Optional] Set up quarto website of analysis",
    "text": "[Optional] Set up quarto website of analysis\nTo render these notebooks as a html pages hosted as a static website.\nI add a file _quarto.yaml into the notebooks folder, with these contents\nproject:\n  type: website\n  output-dir: ../docs\n\n\nwebsite:\n  title: &lt;title of project seen in browser tab&gt;\n  reader-mode: true\n  sidebar: \n    title: &lt;title of project seen in side bar of website&gt;,\n    style: \"docked\"\n    contents:\n      - href: index.qmd # home page\n        text: Home\n      - 00_jl_startcleaningdata.ipynb\n      # - other_analyses_i_have_done.ipynb\n\nformat:\n  html:\n    theme:\n      light: flatly\n      dark: darkly\n    css: styles.css\n    toc: true\nI’ll also add a local .gitignore file to the notebooks folder with lines\n/.quarto/\ncpuprof\nFor the homepage, notebooks/index.md I’ll usually copy in the contents of README.md then edit from there. It should contain a paragraph describing the project at the least.\nTo locally preview the website open a terminal in the notebooks folder either in vscode or externally and enter the command\nquarto preview \nAs you edit the notebooks, the website will automatically update with the changes.\nWhen you’re project is finished, the website can be hosted on GitHub Pages\nSee this quarto tutorial for setting that up."
  },
  {
    "objectID": "blogposts/001_setting-up-an-analysis-project.html#other-tips",
    "href": "blogposts/001_setting-up-an-analysis-project.html#other-tips",
    "title": "Setting up a reproducible Julia, Python, R data analysis projects",
    "section": "Other tips",
    "text": "Other tips\nThe other common bit of advice I give to people starting with scientific data analysis is to get in the habit of gradually turning your code into packages. This is a process. As you are playing around with the data, your code will inevitably start messy. But, notice when you start copy/pasting chunks of code. Those are the pieces that should probably be functions. So, take the time to make them functions. Once you have a few functions related to a topic, throw them into a new file in the src folder. And then import/include them into your analysis code. This promotes consistancy and reproducibility across your analyses.\nJulia example:\ninclude(srcdir(\"myfunctionsfor_x.jl\"))\n# if revise is loaded (which the julia extension should do automatically)\n# use \nincludet(srcdir(\"myfunctionsfor_x.jl\"))\n# for include&lt;tracked&gt; which will update every time the included file is saved\nPython example:\nfrom path.to.myfunctionsfor_x import myfunction\nFor python, If your analysis code is in notebooks folder, then create a src folder in there to hold your function files. Python really doesn’t like importing things from sibling folders.\nAfter you have a few of those files, or the functions have solidified and you are not making any more edits to them, look up how to turn them into a full package."
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "An evolution-based framework for describing human gut bacteria BioRxiv | Dec 5, 2023 https://doi.org/10.1101/2023.12.04.569969\nConcerted changes in the pediatric single-cell intestinal ecosystem before and after anti-TNF blockade eLife | Sep 22, 2023 https://doi.org/10.7554/eLife.91792.1\nSingle-cell profiling of environmental enteropathy reveals signatures of epithelial remodeling and immune activation in severe disease Science Translational Medicine | Jan 1, 2022 https://doi.org/10.1126/scitranslmed.abi8633\nInflammasomes within hyperactive murine dendritic cells stimulate long-lived T cell-mediated anti-tumor immunity Cell Reports | Nov 17, 2020 https://doi.org/10.1016/j.celrep.2020.108381\nSARS-CoV-2 receptor ACE2 is an interferon-stimulated gene in human airway epithelial cells and is detected in specific cell subsets across tissues Cell | May 28, 2020 https://doi.org/10.1016/j.cell.2020.04.035"
  }
]